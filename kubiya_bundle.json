{
  "tools": [
    {
      "name": "say_hello",
      "source": null,
      "alias": null,
      "description": "Greets person in a random movie star way",
      "type": "docker",
      "content": "\npip install litellm==1.59.5\n\npython /tmp/main.py --name \"{{ .name }}\"\n",
      "content_url": null,
      "args": [
        {
          "name": "name",
          "type": null,
          "description": "name to say hello to",
          "required": true,
          "default": null,
          "options": null,
          "options_from": null
        }
      ],
      "env": [
        "LLM_API_KEY",
        "LLM_BASE_URL"
      ],
      "secrets": [],
      "dependencies": null,
      "dependencies_url": null,
      "openapi": null,
      "with_files": [
        {
          "source": null,
          "destination": "/tmp/main.py",
          "content": "import os\nimport litellm\nimport argparse\n\n\ndef main_func(name: str):\n    llm_key = os.environ[\"LLM_API_KEY\"]\n    llm_base_url = os.environ[\"LLM_BASE_URL\"]\n    try:\n        print(\"Calling llm\")\n        response = litellm.completion(\n            model=\"openai/gpt-4o\",\n            api_key=llm_key,\n            base_url=llm_base_url,\n            messages=[\n                {\n                    \"content\": f\"Your task it to great people in a random movie star way, you must say which movie star you choose\",\n                    \"role\": \"system\",\n                },\n                {\"content\": f\"My name is {name}, greet me!\", \"role\": \"user\"},\n            ],\n        )\n    except Exception as e:\n        print(e)\n        print(\"tool ended with error\")\n        return\n\n    print(response.choices[0].message.content)\n    print(\"tool ended successfully\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--name\", type=str, required=True)\n    args = parser.parse_args()\n    main_func(args.name)\n"
        }
      ],
      "with_services": [],
      "with_git_repo": null,
      "with_volumes": [],
      "entrypoint": [],
      "icon_url": null,
      "image": "python:3.12-slim-bullseye",
      "long_running": false,
      "on_start": null,
      "on_build": null,
      "on_complete": null,
      "mermaid": "graph TD\n    %% Styles\n    classDef triggerClass fill:#3498db,color:#fff,stroke:#2980b9,stroke-width:2px,font-weight:bold\n    classDef paramClass fill:#2ecc71,color:#fff,stroke:#27ae60,stroke-width:2px\n    classDef execClass fill:#e74c3c,color:#fff,stroke:#c0392b,stroke-width:2px,font-weight:bold\n    classDef envClass fill:#f39c12,color:#fff,stroke:#f1c40f,stroke-width:2px\n\n    %% Main Components\n    Trigger(\"Trigger\"):::triggerClass\n    Params(\"Parameters\"):::paramClass\n    Exec(\"say_hello\"):::execClass\n    Env(\"Environment\"):::envClass\n\n    %% Flow\n    Trigger --> Params --> Exec\n    Env --> Exec\n\n    %% Trigger Options\n    User(\"User\")\n    API(\"API\")\n    Webhook(\"Webhook\")\n    Cron(\"Scheduled\")\n    User --> Trigger\n    API --> Trigger\n    Webhook --> Trigger\n    Cron --> Trigger\n\n    %% Parameters\n    subgraph Parameters[\"Parameters\"]\n        direction TB\n        Param0(\"name (Required)<br/>name to say hello to\"):::paramClass\n    end\n    Parameters --- Params\n\n    %% Execution\n    subgraph Execution[\"Execution\"]\n        direction TB\n        Code(\"Script: <br/>pip install litellm==1.59.5<br/><br/>python /tmp/main.py ...\")\n        Type(\"Type: Docker\")\n        Image(\"Docker Image: python:3.12-slim-bullseye\")\n    end\n    Execution --- Exec\n\n    %% Environment\n    subgraph Environment[\"Environment\"]\n        direction TB\n        EnvVars(\"Environment Variables:<br/>LLM_API_KEY<br/>LLM_BASE_URL\"):::envClass\n    end\n    Environment --- Env\n\n    %% Context Note\n    ContextNote(\"Parameter values can be<br/>fetched from context<br/>based on the trigger\")\n    ContextNote -.-> Params",
      "workflow": false,
      "metadata": {}
    }
  ],
  "errors": [],
  "python_bundle_version": "3.12.2"
}